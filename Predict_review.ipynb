{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpCa78kOnu8w"
      },
      "source": [
        "# **Predict the score and class of Hotel's reviews**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ld7AyEyaneh-"
      },
      "source": [
        "The notebook aims to develop a model to predict both the score and the class of reviews combining a bidirectionl RNN and a Dense Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "XGRa71Emwuh3"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "!pip install --upgrade tensorflow keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OMEmEwvCvMB"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PexviLaSnS90"
      },
      "source": [
        "# Import the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VkEffBwF0wTF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Download CSV using GitHub\n",
        "url = \"https://raw.githubusercontent.com/jcerri23/DLexam/refs/heads/main/input_data.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muzcbzdJp5Rc"
      },
      "source": [
        "The `Review_Score` ans the `Review_Type `columns will be our target columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHr_UFkGp2G2"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pe7ubrmUnWmY"
      },
      "source": [
        "## Pre processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKSx_TSEsAGj"
      },
      "source": [
        "The two main pre processing steps are performed on the `Review_Type` column and on the `Review` field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFLx5Ah0qNl8"
      },
      "outputs": [],
      "source": [
        "df['Review_Type'] = df['Review_Type'].replace({'Good_review': 1, 'Bad_review': 0})\n",
        "df['Review_Type']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rp3SosaltDTU"
      },
      "source": [
        "There are quite the same number of reviews that belong to the positive and negative class, with respect of this feature the dataset is BALANCED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3cickx0pSaP"
      },
      "outputs": [],
      "source": [
        "# checking balance\n",
        "y2 = df['Review_Type']\n",
        "\n",
        "print(f\"Number of 0:{(y2==0).sum()}\")\n",
        "print(f\"Number of 1:{(y2==1).sum()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBo6OxkY0Jzr"
      },
      "source": [
        "A minimal cleaming will be perfomed on the review text :\n",
        "\n",
        "- Normalize all words to lowercase to reduce the vocabulary size\n",
        "- Remove all punctuation, numbers and special characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9waz1tow0OIN"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def cleaning(text):\n",
        "    text = text.lower() # LOWERCASE\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)  # REMOVE punctuation, numbers, special characters\n",
        "    return text\n",
        "\n",
        "df['Review'] = df['Review'].astype(str).apply(cleaning)\n",
        "\n",
        "# rename the review column\n",
        "df.rename(columns={'Review': 'Clean_Review'}, inplace=True)\n",
        "df['Clean_Review'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNxhx7ZZwH84"
      },
      "source": [
        "# Splitting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "479tWNoZwLZ9"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import dataclass_transform\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['Clean_Review']\n",
        "y = df[['Review_Score', 'Review_Type']]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NOiu7Y24u7_"
      },
      "source": [
        "# Tokenization and Padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcC_PLvP5mOy"
      },
      "source": [
        "In order to prepare the data for the first layer of the model, the `EmbeddingLayer`, we need to idenify the number of unique words in the reviews, build a mapping from each unique word to an index.\n",
        "\n",
        "To avoid data leakage a `Tokenizer` is used to learn the word-to-index mapping only on train dataset\n",
        "\n",
        "At last all sequences are pad at the same length using the `pad_sequences` function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqIFmy7o5guv"
      },
      "outputs": [],
      "source": [
        "all_words = [word for review in df['Clean_Review'] for word in review.split()]\n",
        "print(f\"Total words: {len(all_words)}\")\n",
        "\n",
        "VOCAB_SIZE = len(set(all_words))\n",
        "print(f\"Unique words: {VOCAB_SIZE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8llwhzIu4yMj"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# split the review in token\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)  # only on train data\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuOtvB539QpJ"
      },
      "source": [
        "Choosing an appropriate `MAX_LENGTH` value is a crucial point to reduce model complexity while maintaining performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMseKSCK8nSB"
      },
      "outputs": [],
      "source": [
        "# Just for the analysis of the MAX_LENGTH\n",
        "review_lengths = df['Clean_Review'].apply(lambda x: len(x.split()))\n",
        "print(review_lengths.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80_dUyWN_u4L"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df['Clean_Review'].apply(lambda x: len(x.split())).hist(bins=50)\n",
        "plt.xlabel('Review Length (words)')\n",
        "plt.ylabel('Number of Reviews')\n",
        "plt.title('Distribution of Review Lengths')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekNFA7ZKA84K"
      },
      "source": [
        "Although the maximum number of words per review is stated as 400, analysis shows that 75% of the reviews are under 30 words.\n",
        "\n",
        "Setting `MAX_LENGTH` to 256 can be a safe and efficient choice, given the distribution, even 128 could be a valid option"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAROvDg-9PwH"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 256\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrdfdvTH7Syg"
      },
      "outputs": [],
      "source": [
        "X_train_pad[367]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtoXYcUgBTxi"
      },
      "source": [
        "# Input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwzhqXzkBaQm"
      },
      "source": [
        "The given dataset has been trasformed into an input of size `(N^SAMPLE, MAX_LENGTH) `"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3jqlm21BEG8"
      },
      "outputs": [],
      "source": [
        "print(\"X_train_pad shape:\", X_train_pad.shape)\n",
        "print(\"X_test_pad shape:\", X_test_pad.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0_tV38zMRNZ"
      },
      "source": [
        "# Initial Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ctd8Yj_V4N_N"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM = 128\n",
        "n_units = 64\n",
        "n_hidden = 64\n",
        "input_seq = Input(shape=(MAX_LEN,), name='input')\n",
        "\n",
        "# Embedding layer\n",
        "x = Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDDING_DIM, input_length=MAX_LEN)(input_seq)\n",
        "\n",
        "# Bidirectional LSTM layer\n",
        "x = Bidirectional(LSTM(n_units, return_sequences=False))(x)\n",
        "\n",
        "# dense + dropout layers\n",
        "x = Dense(n_hidden, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "\n",
        "#  Regression head\n",
        "output_score = Dense(1, activation='linear', name='score_output')(x)\n",
        "\n",
        "# Classification head\n",
        "output_class = Dense(1, activation='sigmoid', name='class_output')(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=input_seq,\n",
        "              outputs=[output_score, output_class]\n",
        "              )\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001, clipvalue=1.0)\n",
        "\n",
        "\n",
        "# Composite loss\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss={\n",
        "        'score_output': 'mse',          # regression loss\n",
        "        'class_output': 'binary_crossentropy'  # classification loss\n",
        "    },\n",
        "    metrics={\n",
        "        'score_output': ['mse'],\n",
        "        'class_output': ['accuracy']\n",
        "    }\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PwEB2F1BEcHN"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyV8wTfaGR2n"
      },
      "source": [
        "Just verify if the model works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WO9T0gqnFe6a"
      },
      "outputs": [],
      "source": [
        "y_train_score = y_train['Review_Score'].values.reshape(-1, 1)\n",
        "y_train_class = y_train['Review_Type'].values.reshape(-1, 1)\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 5\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    X_train_pad,\n",
        "    y={'score_output':y_train_score, 'class_output': y_train_class},\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDkv03T9OG1z"
      },
      "source": [
        "Without any special parameters the models seems to has already  good performances, with an accuracy of 90% into predicting the classo of the review and small errors on the score prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOxa8vtPikfL"
      },
      "source": [
        "\n",
        " - val_class_output_accuracy: 0.8975\n",
        " - val_class_output_loss: 0.3148\n",
        " - val_loss: 2.2076\n",
        " - val_score_output_loss: 1.9724\n",
        " - val_score_output_mse: 1.9011\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ezmk0p1Li-ev"
      },
      "source": [
        "# Hyperparameters tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exp5AEgGmb0a"
      },
      "source": [
        "\n",
        "The key parameters worth tuning in the context of the Bidirectional LSTM are the `number of units` and the `number of epochs` .\n",
        "\n",
        "Additionally, when encoding the text, finding the optimal `embedding size` can be very beneficial.\n",
        "\n",
        "Finally, tuning regularization parameters such as the `dropout rate` and the optimizer’s `clip value` may further enhance model performance.\n",
        "\n",
        "* Number of units\n",
        "* Number of epochs\n",
        "* Embedding size\n",
        "* Dropout rate\n",
        "* Clip value\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na2ZeU8Fx7Ae"
      },
      "source": [
        "We can introduce an EarlyStopping callback to avoid performing unnecessary epoch if validation loss stops to increase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRWOOmpDyXz_"
      },
      "source": [
        "Then a function can be defined to build the model and test the values of the hyperparameters chosen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3qsqAp84whO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# EarlyStopping callback\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=0\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLwAELYf2ap7"
      },
      "source": [
        "The initial model achieved a total loss of 2.017, which serves as our baseline for comparison (look at Initial Model section)\n",
        "\n",
        "Inspecting the loss components, it became evident that the regression loss is significantly higher than the classification loss.\n",
        "\n",
        "* `score_output_loss ≈ 1.9`\n",
        "* `class_output_loss ≈ 0.3`\n",
        "\n",
        "This discrepancy causes the total loss to be dominated by the regression task, since Keras by default computes the total loss as a simple sum of the individual task losses.\n",
        "\n",
        "\n",
        "To address this imbalance and ensure that both tasks contribute more equally to model training, we manually assigned custom weights to each loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqXM6j2C4zna"
      },
      "outputs": [],
      "source": [
        "# builder function with weigthed loss\n",
        "\n",
        "def create_model(VOCAB_SIZE, MAX_LEN, EMBEDDING_DIM, n_units, dropout_rate, clipvalue):\n",
        "    input_ = Input(shape=(MAX_LEN,))\n",
        "    x = Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDDING_DIM, input_length=MAX_LEN)(input_)\n",
        "    x = Bidirectional(LSTM(n_units, return_sequences=False))(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    score_output = Dense(1, name='score_output')(x)  # Regression\n",
        "    class_output = Dense(1, activation='sigmoid', name='class_output')(x)  # Classification\n",
        "\n",
        "    model = Model(inputs=input_, outputs=[score_output, class_output])\n",
        "\n",
        "    optimizer = Adam(learning_rate=0.001, clipvalue=clipvalue)\n",
        "\n",
        "    model.compile(\n",
        "    loss={\n",
        "        'score_output': 'mse',\n",
        "        'class_output': 'binary_crossentropy'\n",
        "    },\n",
        "    loss_weights={\n",
        "        'score_output': 0.5,   # downweight the regression task\n",
        "        'class_output': 1.0    # emphasize classification\n",
        "    },\n",
        "    metrics={\n",
        "        'score_output': ['mse'],\n",
        "        'class_output': ['accuracy']\n",
        "    }\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrZzIrQEzA8E"
      },
      "source": [
        "Defining for each parameter the acceptable range of values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPDyzfXp41Z-"
      },
      "outputs": [],
      "source": [
        "param_distributions = {\n",
        "    'n_units': [8,16,32,64],\n",
        "    'EMBEDDING_DIM': [32, 64, 128],\n",
        "    'dropout_rate': [0.2, 0.3, 0.5],\n",
        "    'clipvalue': [0.5, 1.0, 2.0],\n",
        "    'epochs': [4,5,6]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efM2-FN45Ccn"
      },
      "source": [
        "**INITIAL PROPOSAL**\n",
        "\n",
        "My initial approach was to perform Stratified K-Fold Cross-Validation based on the classification labels.\n",
        "\n",
        "This is a robust and reliable method for model evaluation, but in practice, it proved to be quite time-consuming, taking approximately 15 minutes per tuning session, likely due to memory and computational limitations.\n",
        "\n",
        "This is the result obtained\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Best hyperparameters found:\n",
        "{'n_units': 64, 'EMBEDDING_DIM': 64, 'dropout_rate': 0.2, 'clipvalue': 0.5, 'epochs': 5}\n",
        "Best average validation loss: 1.0737\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TanqIvLA6pDw"
      },
      "outputs": [],
      "source": [
        "# SKIP THIS PART AND PERFORM THE FASTER TUNING ABOVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCZvyh1j4n44"
      },
      "outputs": [],
      "source": [
        "n_trials = 7\n",
        "\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "best_avg_val_loss = float('inf')\n",
        "best_params = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6JXQ_ImzjvXn",
        "outputId": "58ec0c6e-f677-4576-b81d-af1e97056249"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Trial 1/7\n",
            "Testing parameters: {'n_units': 8, 'EMBEDDING_DIM': 32, 'dropout_rate': 0.5, 'clipvalue': 1.0, 'epochs': 4}\n",
            "  Fold 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Validation loss: 1.1498\n",
            "  Fold 2\n",
            "    Validation loss: 1.1323\n",
            "  Fold 3\n",
            "    Validation loss: 1.1127\n",
            "  ➤ Avg validation loss: 1.1316\n",
            "\n",
            " Trial 2/7\n",
            "Testing parameters: {'n_units': 32, 'EMBEDDING_DIM': 32, 'dropout_rate': 0.2, 'clipvalue': 1.0, 'epochs': 4}\n",
            "  Fold 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Validation loss: 1.0190\n",
            "  Fold 2\n",
            "    Validation loss: 1.1119\n",
            "  Fold 3\n",
            "    Validation loss: 1.0540\n",
            "  ➤ Avg validation loss: 1.0616\n",
            "\n",
            " Trial 3/7\n",
            "Testing parameters: {'n_units': 16, 'EMBEDDING_DIM': 64, 'dropout_rate': 0.3, 'clipvalue': 0.5, 'epochs': 6}\n",
            "  Fold 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Validation loss: 0.9942\n",
            "  Fold 2\n",
            "    Validation loss: 1.0950\n",
            "  Fold 3\n",
            "    Validation loss: 1.0058\n",
            "  ➤ Avg validation loss: 1.0317\n",
            "\n",
            " Trial 4/7\n",
            "Testing parameters: {'n_units': 64, 'EMBEDDING_DIM': 64, 'dropout_rate': 0.5, 'clipvalue': 1.0, 'epochs': 4}\n",
            "  Fold 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Validation loss: 1.1077\n",
            "  Fold 2\n",
            "    Validation loss: 1.1453\n",
            "  Fold 3\n",
            "    Validation loss: 1.0848\n",
            "  ➤ Avg validation loss: 1.1126\n",
            "\n",
            " Trial 5/7\n",
            "Testing parameters: {'n_units': 8, 'EMBEDDING_DIM': 128, 'dropout_rate': 0.5, 'clipvalue': 1.0, 'epochs': 6}\n",
            "  Fold 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Validation loss: 1.0299\n",
            "  Fold 2\n",
            "    Validation loss: 1.0923\n",
            "  Fold 3\n",
            "    Validation loss: 1.0888\n",
            "  ➤ Avg validation loss: 1.0703\n",
            "\n",
            " Trial 6/7\n",
            "Testing parameters: {'n_units': 32, 'EMBEDDING_DIM': 32, 'dropout_rate': 0.2, 'clipvalue': 0.5, 'epochs': 6}\n",
            "  Fold 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "for trial in range(n_trials):\n",
        "    print(f\"\\n Trial {trial+1}/{n_trials}\")\n",
        "\n",
        "    # Sample hyperparameters\n",
        "    params = {k: random.choice(v) for k, v in param_distributions.items()}\n",
        "    print(\"Testing parameters:\", params)\n",
        "\n",
        "    fold_val_losses = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_pad, y_train_class)):\n",
        "        print(f\"  Fold {fold+1}\")\n",
        "\n",
        "        X_tr, X_val = X_train_pad[train_idx], X_train_pad[val_idx]\n",
        "        y_score_tr, y_score_val = y_train_score[train_idx], y_train_score[val_idx]\n",
        "        y_class_tr, y_class_val = y_train_class[train_idx], y_train_class[val_idx]\n",
        "\n",
        "        model = create_model(\n",
        "            VOCAB_SIZE=VOCAB_SIZE,\n",
        "            MAX_LEN=MAX_LEN,\n",
        "            EMBEDDING_DIM=params['EMBEDDING_DIM'],\n",
        "            n_units=params['n_units'],\n",
        "            dropout_rate=params['dropout_rate'],\n",
        "            clipvalue=params['clipvalue']\n",
        "        )\n",
        "\n",
        "        model.fit(\n",
        "            X_tr,\n",
        "            {'score_output': y_score_tr, 'class_output': y_class_tr},\n",
        "            epochs=params['epochs'],\n",
        "            batch_size=32,\n",
        "            verbose=0,\n",
        "            validation_data=(X_val, {'score_output': y_score_val, 'class_output': y_class_val}),\n",
        "            callbacks=[early_stop]\n",
        "        )\n",
        "\n",
        "        # evaluate the trial model on the validation\n",
        "        val_loss = model.evaluate(\n",
        "            X_val,\n",
        "            {'score_output': y_score_val, 'class_output': y_class_val},\n",
        "            verbose=0\n",
        "        )[0]  # total loss\n",
        "\n",
        "        print(f\"    Validation loss: {val_loss:.4f}\")\n",
        "        fold_val_losses.append(val_loss)\n",
        "\n",
        "    avg_val_loss = np.mean(fold_val_losses)\n",
        "    print(f\"  ➤ Avg validation loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    if avg_val_loss < best_avg_val_loss:\n",
        "        best_avg_val_loss = avg_val_loss\n",
        "        best_params = params\n",
        "\n",
        "# 15 minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xESNknYh0_T3"
      },
      "outputs": [],
      "source": [
        "# Final result\n",
        "print(\"\\nBest hyperparameters found:\")\n",
        "print(best_params)\n",
        "print(f\"Best average validation loss: {best_avg_val_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la01Conm521M"
      },
      "source": [
        "**CHANGE --> Holdout setting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ7q60_f6kEy"
      },
      "source": [
        "To speed up the process, I switched to performing hyperparameter tuning using a holdout validation split.\n",
        "\n",
        "While slightly less robust than K-Fold, this method significantly reduces computation time and still provides meaningful performance estimates during model selection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IiItikH6E1R"
      },
      "outputs": [],
      "source": [
        "# Holdout validation split (stratified)\n",
        "X_tr, X_val, y_score_tr, y_score_val, y_class_tr, y_class_val = train_test_split(\n",
        "    X_train_pad, y_train_score, y_train_class,\n",
        "    test_size=0.2,\n",
        "    stratify=y_train_class,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "best_params = None\n",
        "\n",
        "# Run random search\n",
        "for trial in range(n_trials):\n",
        "    print(f\"\\nTrial {trial+1}/{n_trials}\")\n",
        "\n",
        "    # Sample random parameters\n",
        "    params = {k: random.choice(v) for k, v in param_distributions.items()}\n",
        "    print(\"Testing parameters:\", params)\n",
        "\n",
        "\n",
        "    model = create_model(\n",
        "        VOCAB_SIZE=VOCAB_SIZE,\n",
        "        MAX_LEN=MAX_LEN,\n",
        "        EMBEDDING_DIM=params['EMBEDDING_DIM'],\n",
        "        n_units=params['n_units'],\n",
        "        dropout_rate=params['dropout_rate'],\n",
        "        clipvalue=params['clipvalue']\n",
        "    )\n",
        "\n",
        "    # Train with early stopping\n",
        "    model.fit(\n",
        "        X_tr,\n",
        "        {'score_output': y_score_tr, 'class_output': y_class_tr},\n",
        "        epochs=params['epochs'],\n",
        "        batch_size=32,\n",
        "        verbose=0,\n",
        "        validation_data=(X_val, {'score_output': y_score_val, 'class_output': y_class_val}),\n",
        "        callbacks=[early_stop]\n",
        "    )\n",
        "\n",
        "    # Evaluate total loss\n",
        "    val_loss = model.evaluate(\n",
        "        X_val,\n",
        "        {'score_output': y_score_val, 'class_output': y_class_val},\n",
        "        verbose=0\n",
        "    )[0]\n",
        "\n",
        "\n",
        "    print(f\"  ➤ Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_params = params\n",
        "\n",
        "\n",
        "print(\"\\nBest hyperparameters:\")\n",
        "print(best_params)\n",
        "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
        "\n",
        "# 4 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ht7IAIB_ucf"
      },
      "source": [
        "The best configuration found is"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WphI6k6C9Euf"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "Best hyperparameters:\n",
        "{'n_units': 8, 'EMBEDDING_DIM': 128, 'dropout_rate': 0.3, 'clipvalue': 2.0, 'epochs': 4}\n",
        "Best validation loss: 1.0067\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pDllFmt8Bzq"
      },
      "source": [
        "# Re-train the model with the best configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTa_9JtHLhew"
      },
      "source": [
        "\n",
        "After the best configuration has been found a standard approach is to re-train the final model on the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhqtLshsLA6Y"
      },
      "outputs": [],
      "source": [
        "best_config = {\n",
        "    'n_units': 8,\n",
        "    'EMBEDDING_DIM': 128,\n",
        "    'dropout_rate': 0.3,\n",
        "    'clipvalue': 2.0,\n",
        "    'epochs': 6\n",
        "}\n",
        "\n",
        "final_model2= create_model(\n",
        "    VOCAB_SIZE=VOCAB_SIZE,\n",
        "    MAX_LEN=MAX_LEN,\n",
        "    EMBEDDING_DIM= 128,\n",
        "    n_units=8,\n",
        "    dropout_rate=0.3,\n",
        "    clipvalue=2.0\n",
        ")\n",
        "\n",
        "final_model2.fit(\n",
        "    X_train_pad,\n",
        "    {'score_output': y_train_score, 'class_output': y_train_class},\n",
        "    epochs=best_config['epochs'],\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InazVf5qIa-R"
      },
      "source": [
        "# Experiment : Autoencoder to learn embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2AjP_naIlqY"
      },
      "source": [
        "BUILD THE AUTOENCODER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJuOgLTzIiIW"
      },
      "outputs": [],
      "source": [
        "def build_autoencoder(VOCAB_SIZE, EMBEDDING_DIM, MAX_LEN):\n",
        "    input_seq = Input(shape=(MAX_LEN,), name='input_seq')\n",
        "\n",
        "    # Encoder\n",
        "    embed = Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDDING_DIM, name='embedding')(input_seq)\n",
        "    encoded = LSTM(64)(embed)\n",
        "\n",
        "    # Decoder\n",
        "    decoded = Dense(VOCAB_SIZE, activation='softmax', name='decoder')(encoded)\n",
        "\n",
        "    autoencoder = Model(inputs=input_seq, outputs=decoded)\n",
        "\n",
        "    autoencoder.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "    return autoencoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vFWNmNcIq5x"
      },
      "source": [
        "COSTUM TASK : PREDICT THE CENTRAL TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQJvWZKoJ1pZ"
      },
      "source": [
        "Instead of reconstructing the entire input sequence, the autoencoder is trained to predict the middle token of the padded input sequence (`X_train_pad[:, MAX_LEN // 2]`).\n",
        "\n",
        "This custom task encourages the model to learn meaningful semantic representations in the embedding layer, which are then used as input features for the BiLSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89k14xjyIo31"
      },
      "outputs": [],
      "source": [
        "y_auto = np.expand_dims(X_train_pad[:, MAX_LEN // 2], axis=1)\n",
        "\n",
        "autoencoder = build_autoencoder(VOCAB_SIZE=VOCAB_SIZE, EMBEDDING_DIM=128, MAX_LEN=MAX_LEN)\n",
        "\n",
        "autoencoder.fit(\n",
        "    X_train_pad,\n",
        "    y_auto,\n",
        "    batch_size=32,\n",
        "    epochs=5,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upixT8snIxxV"
      },
      "source": [
        "FEED THE MODEL WITH THE LEARNED EMBEDDINGS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nv9YazxpIxe4"
      },
      "outputs": [],
      "source": [
        "# Get the trained embedding layer weights\n",
        "embedding_weights = autoencoder.get_layer('embedding').get_weights()\n",
        "\n",
        "def create_model_with_ae_embedding(VOCAB_SIZE, MAX_LEN, EMBEDDING_DIM, n_units, dropout_rate, clipvalue, embedding_weights):\n",
        "    input_ = Input(shape=(MAX_LEN,))\n",
        "\n",
        "    # AUTOENCODER EMBEDDING\n",
        "    x = Embedding(\n",
        "        input_dim=VOCAB_SIZE,\n",
        "        output_dim=EMBEDDING_DIM,\n",
        "        weights=embedding_weights,\n",
        "        trainable=True, # update embedding during training\n",
        "        name=\"pretrained_embedding\"\n",
        "    )(input_)\n",
        "\n",
        "    x = Bidirectional(LSTM(n_units, return_sequences=False))(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    score_output = Dense(1, name='score_output')(x)\n",
        "    class_output = Dense(1, activation='sigmoid', name='class_output')(x)\n",
        "\n",
        "    model = Model(inputs=input_, outputs=[score_output, class_output])\n",
        "\n",
        "    optimizer = Adam(learning_rate=0.001, clipvalue=clipvalue)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss={\n",
        "            'score_output': 'mse',\n",
        "            'class_output': 'binary_crossentropy'\n",
        "        },\n",
        "        loss_weights={\n",
        "            'score_output': 0.5,\n",
        "            'class_output': 1.0\n",
        "        },\n",
        "        metrics={\n",
        "            'score_output': ['mse'],\n",
        "            'class_output': ['accuracy']\n",
        "        }\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsOArfWNI4AH"
      },
      "source": [
        "COMPARE PERFORMANCES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLsrLz9lI6_e"
      },
      "outputs": [],
      "source": [
        "final_model1 = create_model_with_ae_embedding(\n",
        "    VOCAB_SIZE=VOCAB_SIZE,\n",
        "    MAX_LEN=MAX_LEN,\n",
        "    EMBEDDING_DIM=128,\n",
        "    n_units=32,\n",
        "    dropout_rate=0.3,\n",
        "    clipvalue=2.0,\n",
        "    embedding_weights=embedding_weights\n",
        ")\n",
        "\n",
        "final_model1.fit(\n",
        "    X_train_pad,\n",
        "    {'score_output': y_train_score, 'class_output': y_train_class},\n",
        "    epochs=4,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76TtYK-rKWwb"
      },
      "source": [
        "Using pretrained embeddings from the autoencoder gives promising results leading to good classification accuracy and moderate score loss.\n",
        "\n",
        "However, the overall  loss  is very close to the baseline with the standard embedding layer trained from scratch .\n",
        "\n",
        "- Best loss with EmbeddingLayer --> `1.1304`\n",
        "- Best loss with AE embedding --> `1.2057`\n",
        "\n",
        "In this case, pretrained embeddings don’t significantly improve performance, so the straightforward standard approach will be maintained.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mt-KRt2I8FeC"
      },
      "source": [
        "# Final Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPG6R7AcMIz8"
      },
      "source": [
        "Finally, the best model should be evaluated on unseen data to assess its generalization ability and to detect any signs of overfitting.\n",
        "\n",
        "Two different metrics can be used to quantify performance on the respective tasks:\n",
        "\n",
        "- **Type classification – Accuracy**\n",
        "\n",
        "  This metric indicates how often the model correctly predicts the class label.\n",
        "  Also f1 score metric is an effective metric, but in this context, since the \"bad\" and \"good\" classes are balanced, we can confidently rely on accuracy to provide a reliable assessment of the model's performance.\n",
        "\n",
        "- **Score prediction – Mean Squared Error (MSE)**\n",
        "\n",
        "  MSE measures the average squared difference between the predicted scores and the actual scores, providing an indication of how far off the predictions are from the true values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yr2UMFZ-EgyL"
      },
      "outputs": [],
      "source": [
        "# prompt: EVALUATE MODEL PERFORMANCES\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "y_pred = final_model2.predict(X_test_pad)\n",
        "\n",
        "y_pred_score = y_pred[0]\n",
        "y_pred_class = y_pred[1]\n",
        "\n",
        "#  Score Prediction (Regression)\n",
        "mse_score = mean_squared_error(y_test['Review_Score'], y_pred_score)\n",
        "mae_score = mean_absolute_error(y_test['Review_Score'], y_pred_score)\n",
        "\n",
        "print(\"--- Score Prediction Performance ---\")\n",
        "print(f\"Mean Squared Error (MSE): {mse_score:.4f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_score:.4f}\")\n",
        "\n",
        "#  Class Prediction (Classification)\n",
        "y_pred_class_labels = (y_pred_class > 0.5).astype(int)\n",
        "\n",
        "accuracy_class = accuracy_score(y_test['Review_Type'], y_pred_class_labels)\n",
        "report_class = classification_report(y_test['Review_Type'], y_pred_class_labels)\n",
        "\n",
        "\n",
        "print(\"\\n--- Class Prediction Performance ---\")\n",
        "print(f\"Accuracy: {accuracy_class:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report_class)\n",
        "\n",
        "# Optional : Confusion Matrix\n",
        "conf_matrix_class = confusion_matrix(y_test['Review_Type'], y_pred_class_labels)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "conf_matrix_class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prACI0gLPO62"
      },
      "source": [
        "# Bonus : Comparing MSE and MAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YbrdviiPEBt"
      },
      "source": [
        "Computing the MAE alongside the MSE provides valuable insight into the nature of the model’s prediction errors.\n",
        "\n",
        "- `MSE: 1.75`\n",
        "- `MAE: 0.9885`\n",
        "\n",
        "The model demonstrates good overall performance (average MAE <1).\n",
        "\n",
        "However, the MSE is significantly higher (approximately 67% greater than the MAE), it may suggests that while most predictions are close to the true values, there are a few large errors  that disproportionately affect the MSE due to its sensitivity to larger deviations."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
